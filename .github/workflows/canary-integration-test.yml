name: Canary integration tests
on:
  pull_request:
    paths:
    - '**.go'
    - '**.sh'
    - '**.py'
    - 'build/**'
    - 'tests/**'
    - 'images/**'
    - '.github/workflows/**'

jobs:
  canary:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: use local disk and create partitions for osds
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_DATA_PART=${BLOCK}1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --osd-count 2
        sudo lsblk

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master


    - name: validate-yaml
      run: |
        cd cluster/examples/kubernetes/ceph/
        kubectl create -f crds.yaml -f common.yaml
        # skipping folders and some yamls that are only for openshift.
        kubectl create  $(ls -I scc.yaml -I "*-openshift.yaml"  -I "*.sh" -I "*.py" -p | grep -v / | awk ' { print " -f " $1 } ') --dry-run

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        sed -i "s|#deviceFilter:|deviceFilter: $(lsblk|awk '/14G/ {print $1}'| head -1)|g" cluster/examples/kubernetes/ceph/cluster-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/cluster-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/object-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/pool-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/filesystem-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/rbdmirror.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/nfs-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 300 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh all 2
        kubectl -n rook-ceph get pods

    - name: test external script create-external-cluster-resources.py
      run: |
        kubectl -n rook-ceph exec $(kubectl get pod -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}') -- /bin/bash -c "echo \"$(kubectl get pods -o wide -n rook-ceph -l app=rook-ceph-mgr --no-headers=true|head -n1|awk '{print $6"\t"$1}')\" >>/etc/hosts"
        kubectl -n rook-ceph exec $(kubectl get pod -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}') -- mkdir -p /etc/ceph/test-data
        kubectl -n rook-ceph cp cluster/examples/kubernetes/ceph/test-data/ceph-status-out $(kubectl get pod -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}'):/etc/ceph/test-data/
        kubectl -n rook-ceph cp cluster/examples/kubernetes/ceph/create-external-cluster-resources.py $(kubectl get pod -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}'):/etc/ceph
        kubectl -n rook-ceph exec $(kubectl get pod -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}') -- python3 /etc/ceph/create-external-cluster-resources.py --rbd-data-pool-name replicapool

    - name: run external script create-external-cluster-resources.py unit tests
      run: |
        kubectl -n rook-ceph exec $(kubectl get pod -l app=rook-ceph-tools -n rook-ceph -o jsonpath='{.items[0].metadata.name}') -- python3 -m unittest /etc/ceph/create-external-cluster-resources.py
        # write a test file
        # copy the test file
        # execute the test file

    - name: run kubectl-check-ownerreferences
      run: |
        curl -L https://github.com/kubernetes-sigs/kubectl-check-ownerreferences/releases/download/v0.2.0/kubectl-check-ownerreferences-linux-amd64.tar.gz -o kubectl-check-ownerreferences-linux-amd64.tar.gz
        tar xzvf kubectl-check-ownerreferences-linux-amd64.tar.gz
        chmod +x kubectl-check-ownerreferences
        ./kubectl-check-ownerreferences -n rook-ceph

    - name: Upload canary test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: canary
        path: test


  pvc:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: install deps
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: use local disk and create partitions for osds
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_DATA_PART=${BLOCK}1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --osd-count 2
        sudo lsblk

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prerequisites
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        tests/scripts/localPathPV.sh "$BLOCK"
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].encrypted" false
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].count" 2
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].volumeClaimTemplates[0].spec.resources.requests.storage" 6Gi
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c '[ $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'|wc -l) -eq 2 ]; do sleep 5; done'||true
        for prepare in $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do
          kubectl -n rook-ceph logs -f $prepare
          break
        done
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$prepare||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 2
        kubectl -n rook-ceph get pods

    - name: run kubectl-check-ownerreferences
      run: |
        curl -L https://github.com/kubernetes-sigs/kubectl-check-ownerreferences/releases/download/v0.2.0/kubectl-check-ownerreferences-linux-amd64.tar.gz -o kubectl-check-ownerreferences-linux-amd64.tar.gz
        tar xzvf kubectl-check-ownerreferences-linux-amd64.tar.gz
        chmod +x kubectl-check-ownerreferences
        ./kubectl-check-ownerreferences -n rook-ceph

    - name: Upload  pvc test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name:  pvc
        path: test

  pvc-db:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: install deps
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq
        sudo apt-get install -y gdisk

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: use local disk
      run: |
        BLOCK_DATA_PART=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk

    - name: create bluestore partitions and PVCs
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_PART="$BLOCK"2
        DB_PART="$BLOCK"1
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --bluestore-type block.db --osd-count 1
        tests/scripts/localPathPV.sh "$BLOCK_PART" "$DB_PART"

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prerequisites
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].encrypted" false
        cat tests/manifests/test-on-pvc-db.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}')||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 1
        kubectl -n rook-ceph get pods

    - name: Upload pvc-db test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: pvc-db
        path: test

  pvc-db-wal:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: install deps
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq
        sudo apt-get install -y gdisk

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: use local disk
      run: |
        BLOCK_DATA_PART=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk

    - name: create bluestore partitions and PVCs
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_PART="$BLOCK"3
        DB_PART="$BLOCK"1
        WAL_PART="$BLOCK"2
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --bluestore-type block.wal --osd-count 1
        tests/scripts/localPathPV.sh "$BLOCK_PART" "$DB_PART" "$WAL_PART"

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prerequisites
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].encrypted" false
        cat tests/manifests/test-on-pvc-db.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        cat tests/manifests/test-on-pvc-wal.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}')||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 1
        kubectl -n rook-ceph get pods

    - name: Upload pvc-db-wal test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: pvc-db-wal
        path: test

  encryption-pvc:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: install yq
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq

    - name: use local disk and create partitions for osds
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_DATA_PART=${BLOCK}1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --osd-count 2
        sudo lsblk

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prerequisites
      run: |
        tests/scripts/localPathPV.sh $(lsblk --paths|awk '/14G/ {print $1}'| head -1)
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].count" 2
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].volumeClaimTemplates[0].spec.resources.requests.storage" 6Gi
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 2
        kubectl -n rook-ceph get pods
        kubectl -n rook-ceph get secrets
        sudo lsblk

    - name: Upload encryption-pvc test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: encryption-pvc
        path: test

  encryption-pvc-db:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: install deps
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq
        sudo apt-get install -y gdisk

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: use local disk
      run: |
        BLOCK_DATA_PART=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk

    - name: create bluestore partitions and PVCs
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_PART="$BLOCK"2
        DB_PART="$BLOCK"1
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --bluestore-type block.db --osd-count 1
        tests/scripts/localPathPV.sh "$BLOCK_PART" "$DB_PART"

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prerequisites
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        cat tests/manifests/test-on-pvc-db.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}')||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 1
        kubectl -n rook-ceph get pods
        kubectl -n rook-ceph get secrets

    - name: Upload encryption-pvc-db-wal test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: encryption-pvc-db-wal
        path: test

  encryption-pvc-db-wal:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: install deps
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq
        sudo apt-get install -y gdisk

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: use local disk
      run: |
        BLOCK_DATA_PART=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk

    - name: create bluestore partitions and PVCs
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_PART="$BLOCK"3
        DB_PART="$BLOCK"1
        WAL_PART="$BLOCK"2
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --bluestore-type block.wal --osd-count 1
        tests/scripts/localPathPV.sh "$BLOCK_PART" "$DB_PART" "$WAL_PART"

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prerequisites
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        cat tests/manifests/test-on-pvc-db.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        cat tests/manifests/test-on-pvc-wal.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}')||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 1
        kubectl -n rook-ceph get pods
        kubectl -n rook-ceph get secrets

    - name: Upload encryption-pvc-db test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: encryption-pvc-db
        path: test

  encryption-pvc-kms-vault-token-auth:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: install yq
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq

    - name: use local disk and create partitions for osds
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        BLOCK_DATA_PART=${BLOCK}1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk
        tests/scripts/create-bluestore-partitions.sh --disk "$BLOCK" --osd-count 2
        sudo lsblk

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: rook prereq
      run: |
        tests/scripts/localPathPV.sh $(lsblk --paths|awk '/14G/ {print $1}'| head -1)
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy vault
      run: |
        tests/scripts/deploy-validate-vault.sh deploy

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        cat tests/manifests/test-kms-vault.yaml >> tests/manifests/test-cluster-on-pvc-encrypted.yaml
        yq merge --inplace --arrays append tests/manifests/test-cluster-on-pvc-encrypted.yaml tests/manifests/test-kms-vault-spec.yaml
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].count" 2
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].volumeClaimTemplates[0].spec.resources.requests.storage" 6Gi
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/object-test.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}')||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 2
        tests/scripts/validate_cluster.sh rgw
        kubectl -n rook-ceph get pods
        kubectl -n rook-ceph get secrets

    - name: validate vault
      run: |
        tests/scripts/deploy-validate-vault.sh validate
        sudo lsblk

    - name: Upload encryption-pvc-kms-vault-token-auth test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name: encryption-pvc-kms-vault-token-auth
        path: test

  lvm-pvc:
    runs-on: ubuntu-18.04
    steps:
    - name: checkout
      uses: actions/checkout@v2

    - name: setup golang
      uses: actions/setup-go@v2
      with:
        go-version: 1.15

    - name: install deps
      run: |
        sudo wget https://github.com/mikefarah/yq/releases/download/3.4.1/yq_linux_amd64 -O /usr/bin/yq
        sudo chmod +x /usr/bin/yq

    - name: setup minikube
      uses: manusa/actions-setup-minikube@v2.2.0
      with:
        minikube version: 'v1.13.1'
        kubernetes version: 'v1.19.2'
        start args: --memory 6g --cpus=2

    - name: use local disk
      run: |
        BLOCK_DATA_PART=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)1
        sudo dmsetup version||true
        sudo swapoff --all --verbose
        sudo umount /mnt
        # search for the device since it keeps changing between sda and sdb
        sudo wipefs --all --force "$BLOCK_DATA_PART"
        sudo lsblk

    - name: check k8s cluster status
      run: |
        kubectl cluster-info
        kubectl get pods -n kube-system

    - name: build rook
      run: |
        # set VERSION to a dummy value since Jenkins normally sets it for us. Do this to make Helm happy and not fail with "Error: Invalid Semantic Version"
        GOPATH=$(go env GOPATH) make clean && make -j$nproc IMAGES='ceph' VERSION=0 build
        docker images
        docker tag $(docker images|awk '/build-/ {print $1}') rook/ceph:master

    - name: create LV on disk
      run: |
        BLOCK=$(sudo lsblk --paths|awk '/14G/ {print $1}'| head -1)
        sudo sgdisk --zap-all "${BLOCK}"
        VG=test-rook-vg
        LV=test-rook-lv
        sudo pvcreate "$BLOCK"
        sudo vgcreate "$VG" "$BLOCK"
        sudo lvcreate -l 100%FREE -n "${LV}" "${VG}"
        tests/scripts/localPathPV.sh /dev/"${VG}"/${LV}
        kubectl create -f cluster/examples/kubernetes/ceph/crds.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/common.yaml

    - name: deploy rook
      run: |
        kubectl create -f cluster/examples/kubernetes/ceph/operator.yaml
        yq write -i tests/manifests/test-cluster-on-pvc-encrypted.yaml "spec.storage.storageClassDeviceSets[0].encrypted" false
        kubectl create -f tests/manifests/test-cluster-on-pvc-encrypted.yaml
        kubectl create -f cluster/examples/kubernetes/ceph/toolbox.yaml

    - name: wait for prepare pod
      run: |
        timeout 180 sh -c 'until kubectl -n rook-ceph logs -f $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}'); do sleep 5; done'||true
        timeout 60 sh -c 'until kubectl -n rook-ceph logs $(kubectl -n rook-ceph get pod -l app=rook-ceph-osd,ceph_daemon_id=0 -o jsonpath='{.items[*].metadata.name}') --all-containers; do echo "waiting for osd container" && sleep 1; done'||true
        kubectl -n rook-ceph describe job/$(kubectl -n rook-ceph get pod -l app=rook-ceph-osd-prepare -o jsonpath='{.items[*].metadata.name}')||true
        kubectl -n rook-ceph describe deploy/rook-ceph-osd-0||true

    - name: wait for ceph to be ready
      run: |
        mkdir test
        tests/scripts/validate_cluster.sh osd 1
        kubectl -n rook-ceph get pods

    - name: run kubectl-check-ownerreferences
      run: |
        curl -L https://github.com/kubernetes-sigs/kubectl-check-ownerreferences/releases/download/v0.2.0/kubectl-check-ownerreferences-linux-amd64.tar.gz -o kubectl-check-ownerreferences-linux-amd64.tar.gz
        tar xzvf kubectl-check-ownerreferences-linux-amd64.tar.gz
        chmod +x kubectl-check-ownerreferences
        ./kubectl-check-ownerreferences -n rook-ceph

    - name: Upload  pvc test result
      uses: actions/upload-artifact@v2
      if: always()
      with:
        name:  lvm-pvc
        path: test
