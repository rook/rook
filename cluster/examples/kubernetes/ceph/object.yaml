apiVersion: ceph.rook.io/v1
kind: CephObjectStore
metadata:
  name: my-store
  namespace: rook-ceph
spec:
  # The pool spec used to create the metadata pools
  metadataPool:
    failureDomain: host
    replicated:
      # Increase the replication size if you have more than one osd
      size: 1
  # The pool spec used to create the data pool
  dataPool:
    failureDomain: osd
    replicated:
      size: 1
    # If you have at least three osds, erasure coding can be specified
    # erasureCoded:
    #   dataChunks: 2
    #   codingChunks: 1
  # The gaeteway service configuration
  gateway:
    # type of the gateway (s3)
    type: s3
    # A reference to the secret in the rook namespace where the ssl certificate is stored
    sslCertificateRef:
    # The port that RGW pods will listen on (http)
    port: 80
    # The port that RGW pods will listen on (https). An ssl certificate is required.
    securePort:
    # The number of pods in the rgw deployment (ignored if allNodes=true)
    instances: 1
    # Whether the rgw pods should be deployed on all nodes as a daemonset
    allNodes: false
    # The affinity rules to apply to the rgw deployment or daemonset.
    placement:
    #  nodeAffinity:
    #    requiredDuringSchedulingIgnoredDuringExecution:
    #      nodeSelectorTerms:
    #      - matchExpressions:
    #        - key: role
    #          operator: In
    #          values:
    #          - rgw-node
    #  tolerations:
    #  - key: rgw-node
    #    operator: Exists
    #  podAffinity:
    #  podAntiAffinity:
    resources:
    # The requests and limits set here, allow the object store gateway Pod(s) to use half of one CPU core and 1 gigabyte of memory
    #  limits:
    #    cpu: "500m"
    #    memory: "1024Mi"
    #  requests:
    #    cpu: "500m"
    #    memory: "1024Mi"
